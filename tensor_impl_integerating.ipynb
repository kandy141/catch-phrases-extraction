{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in DataSet: 400000\n",
      "shape of data: (866842, 5)\n",
      "Started\n",
      "time-taken: 4.76837158203125e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile,join\n",
    "import xml.etree.cElementTree as ET\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import time\n",
    "#import doc2vec_impl\n",
    "import gensim\n",
    "\n",
    "import FileProcess as fp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print (fp.window_size)\n",
    "batch_size=10\n",
    "vocabulary_size=400000\n",
    "embedding_size=200\n",
    "embedding_filename = \"glove_6B_200d.txt\"\n",
    "training_epochs=1\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  1 on 17 april 2008 the application brought by the university of western australia (uwa) against dr bruce gray and sirtex medical ltd (sirtex) was dismissed.', 'uwa was ordered to pay the costs of dr gray and sirtex.', \"a cross-claim brought by sirtex against uwa was dismissed and sirtex ordered to pay uwa's costs of that cross-claim.\", 'sirtex succeeded in its cross-claim against dr gray.', '2 paragraphs 14 and 15 of the orders made on 17 april 2008 provided:    14.', 'any party in respect of whom an order for costs has been made in the preceding orders is at liberty to file and serve written submissions on or before 8 may 2008 seeking a variation of the costs order.', '15.', 'any party who wishes to respond to a written submission filed pursuant to the preceding order is to do so by filing and serving a written submission by 29 may 2008.', ' 3 on 12 may 2008 sirtex filed a motion seeking the following orders:    1.1 that order 2 of his honour justice french, made on 17 april 2008, be amended to read as follows:   \"applicant pay the first and second respondent\\'s costs of the application and the applicant pay the second respondents\\' costs of the application on an indemnity basis from 19 march 2007.', '\" [sic]  1.2 applicant pay the second respondent\\'s costs of this motion on an indemnity basis.', '1.3 any other order that the court sees fit.', ' in support of its motion, sirtex filed an affidavit of timothy randle price sworn 12 may 2008.', 'that affidavit concerned settlement negotiations between uwa and sirtex which had occurred in 2007 prior to the commencement of the hearing.', '4 by way of background the solicitors for uwa had sent an open settlement offer to sirtex on 5 september 2006.', 'the letter of offer was exhibit 243a at trial.', 'in substance the letter proposed that uwa would licence sirtex, on a world-wide basis, to exploit the patents in contention, the licence to be retroactive to 29 april 1997.', 'a discounted licence fee would be payable.', 'uwa would be recorded as owner of the patents.', 'a 4% royalty on the net price of products using or embodying any claim of any one or more of the patents was proposed.', 'the uwa proceedings against sirtex would be discontinued with no order as to costs.', 'uwa required that sirtex cooperate with it in the further conduct of the proceedings against dr gray.', \"the offer was accompanied by contentions that the directors of sirtex were aware at all material times of uwa's interest in the intellectual property.\", 'the offer was not accepted.', '5 the trial was scheduled to begin in the week commencing monday, 12 march 2007.', 'on saturday, 10 march 2007, the solicitors for uwa again wrote to the solicitors for sirtex making an \"open offer\".', 'the offer was in the following terms:  the university offers to fully and finally settle with sirtex medical limited (sirtex) the above named proceedings on the following basis:   1.', 'within 14 days of the date of settlement, sirtex to pay the university the sum of aud$1.25 million dollars; [sic] and   2.', 'within 30 days of settlement, sirtex to allot and issue to the university fully paid ordinary shares in sirtex ranking pari passu with all existing fully paid shares to the value of aud$3 million dollars [sic] based upon the vwap selling price for sirtex shares for 14 trading days immediately prior to completion of the allotment and issue, which allotment is to provide a fund for the establishment of a scholarship within the university sufficient for an annual award at university postgraduate award rates for the purpose of encouraging students to undertake research in an area of biomedical science ( the sirtex scholarship );   ...  the offer went on to set out the conditions upon which the sirtex scholarship would be awarded.', 'it then continued:   4.', 'the proceedings in wad 292 of 2004 in so far as they subsist between the university and sirtex to be discontinued with no order as to costs.', '5.', 'a deed of release to be executed by the university and sirtex under which both parties will irrevocably release each other from all claims made against each other in the proceedings.', '6.', 'it is a condition precedent to settlement in accordance with this offer that sirtex withdraws its opposition to the implementation of the settlement between the university and the cancer research institute inc, which was approved by the federal court of australia on 9 march 2007.', '7.', 'this offer is an open offer and may be withdrawn at any time prior to acceptance by notice in writing served by the university upon sirtex or its legal representatives in the proceedings.', \" the letter, like its predecessor in september 2006, alleged that, although investors in sirtex had been innocent of uwa's interest in its intellectual property, the directors were aware of that interest.\", \"6 sirtex responded to uwa's offer through its solicitors by a letter dated 14 march 2007, the day prior to the actual commencement of the trial.\", 'in that letter sirtex responded to the allegations about the awareness of its directors which uwa had made in its letter of 10 march 2007.', 'sirtex said, in its letter, that it was inappropriate for uwa to make such allegations as there was no evidence to support them.', 'sirtex nevertheless indicated that it was prepared to resolve the dispute on the terms set out in an attached deed of settlement.', 'it also stated that it was content to consider any reasonable amendments to the deed proposed by uwa provided that they were designed to clarify or perfect its terms, but not otherwise impact on its substance.', 'if the offer were accepted it would no longer be necessary for sirtex to pursue its cross-claim against cri.', 'the letter continued:    7.', \"sirtex notes uwa's interest in a scholarship to be funded by sirtex.\", 'we are instructed that sirtex would be happy to consider such a proposal (or a proposal to sponsor research undertaken at uwa) following the resolution of these proceedings.', ' the offer contained in the letter remained open until 10am on 19 march 2007 at which time it would be withdrawn.', 'sirtex reserved all of its rights and stated it would rely upon the letter to claim indemnity costs from that date.', '7 the deed of settlement attached to the letter provided for a mutual release by uwa and sirtex of each other and their associated entities from all claims made against each other in the proceeding or arising from or in connection with its subject matter including all claims for transfer of ownership of the patents in contention.', \"it also provided for uwa to acknowledge sirtex's ownership of the patents and undertake not to challenge sirtex's entitlement to remain their registered owner.\", \"uwa would undertake to take all reasonably necessary steps to ratify, perfect and/or defend sirtex's registration and/or ownership of the patents as requested by sirtex in writing.\", \"these provisions were stated to be without prejudice to uwa's right to claim against dr gray that it had a beneficial interest in the patents for the purposes of its claim to his shareholding in sirtex.\", \"8 clause 3 of the deed provided:    3.1 if uwa has substantial success against gray in the proceeding, sirtex shall (at sirtex's election) within 28 days of the date of substantial success:   3.1.1 provide uwa with the share allotment; or  3.1.2 pay uwa the settlement amount.\", '3.2 sirtex shall not be liable to provide uwa with the share allotment or the settlement amount in accordance with clause 3.1 of this deed if uwa does not have substantial success against gray in the proceeding.', ' 9 the term \"substantial success\" was defined in clause 8.1 thus:  substantial success means   (i) a final court order in the proceeding (including and subject to any appeal) dealing with the question of ownership of the patents as between uwa and gray (and such order will be deemed not final unless and until the period for filing an appeal against such order as prescribed in the relevant court rules has expired, and such expiry date shall be treated as the date of the final order for the purposes of this deed); or   (ii) any written settlement agreement executed between uwa and gray dealing with the question of ownership of the patents as between uwa and gray and served upon sirtex,   which has the effect of:   (iii) declaring that uwa has been at 17 april 1997 or any later time a beneficial owner of any of the patents;   (iv) transferring more than 10% of gray\\'s shareholding in sirtex to uwa; and/or  (v) gray having a liability to pay uwa an amount of more than 10% of the value of gray\\'s shareholding in sirtex as at the settlement date to be agreed by the parties immediately before the execution of this deed or counterparts to this deed.', ' 10 the settlement amount was defined as \"aud$1.5 million\".', 'the \"share allotment\" was defined as \"an issue of shares in sirtex to the value of $1.5m (rounded up)\".', 'the value of the shares was to be calculated by reference to the volume weighted average price for the five business days commencing two days after the settlement date.', 'the settlement date was defined as \"the date of exchange of the duly executed counterparts of this deed\".', '11 mr price said in his initial affidavit that no response was received to the offer from uwa.', 'that statement was erroneous as he acknowledged in a second affidavit.', 'on 15 march 2007 the solicitors for uwa wrote back to the solicitors for sirtex in the following terms:    1.', 'we refer to your letter dated 14 march 2007 with respect to an offer to settle by sirtex medical limited.', '2.', 'the offer of settlement is unacceptable to our client.', '3.', \"the effect of your offer of 14 march 2007 is to reject our client's offer of 10 march 2007.\", 'that is, it is no longer open to your client to accept it.', ' 12 in the course of closing submissions at the end of the substantive hearing, uwa indicated the orders it would seek to have made against sirtex.', 'the orders it sought in its closing submissions were in the following terms:  the court: 1.', 'makes the declarations sought in order 7 of the second substituted application filed 1 march 2007 (\"the application\").', '2.', 'subject to the undertaking by the applicant in paragraph 3 hereof, makes orders 8 to 10 sought in the application.', '3.', 'notes the undertaking of the applicant to the court that it will not seek to enforce the above order 2 upon the entry by sirtex into a deed whereby the applicant will be entitled to royalties with respect to the intellectual property identified in the attached schedule in an amount as agreed between the parties within 14 days or as ordered by the court upon the appointment and report of an expert pursuant to fcr order 34 rule 2.', '4.', 'order the second respondent to pay the applicant royalties in the amount set in accordance with order 3 above for the period 1 may 1997 to the date of judgment together with interest thereon.', '5.', 'costs.', '13 a proposed deed in accordance with the proposed order 3 was annexed to the submissions.', 'the deed provided for sirtex to pay a royalty in respect of the exploitation of products using or incorporating a claim under any of the patents and patent applications specified in schedule 1 to the deed including any confidential information comprised in or relating to the inventions the subject of the patents.', 'the deed would have contained an acknowledgment by uwa that nothing in it transferred title to the patents to uwa.', 'uwa would have ratified, with effect from the date of execution of the deed, each of the assignments to sirtex pleaded in its statement of claim.', \"the deed included an undertaking by uwa not to challenge or question sirtex's title to or interest in each of the patents, the validity of any of the patents or any application by sirtex to register a trade mark in connection with any of the patents.\", 'it is not necessary to go further into the details of the deed, the substance of it is clear enough from the preceding outline.', '14 on 2 may 2008 the solicitors for sirtex wrote to the solicitors for uwa seeking its consent to an order for indemnity costs.', \"it referred, in particular, to paragraph 1569 and 1570 of the primary judgment in which it was said:  the case against sirtex for knowing involvement in dr gray's alleged breaches of fiduciary duty and knowing assistance depends crucially upon the primary case against dr gray.\", 'that case having failed, the claim against sirtex cannot succeed and will be dismissed.', 'i should add as i have already found that sirtex was not at any time on notice of a potential claim by uwa through any of its directors other than dr gray.', 'the application of any cause of action based on knowing involvement in his alleged breaches of fiduciary duty would have depended entirely upon his role as a director of sirtex and whether his knowledge could be attributed to the company.', '15 on 8 may 2008, the time for filing an appeal from the primary judgment of 17 april 2008 expired.', 'uwa filed a notice of appeal in respect of the dismissal of its application against dr gray.', 'it has not appealed against the dismissal of its application against sirtex.', \"submissions  16 sirtex's primary submission on the hearing of the motion was that uwa acted unreasonably and imprudently in refusing the sirtex offer.\", 'sirtex acknowledged that its success in the cross-claim against dr gray left it open to seek from him, by way of damages, the difference between the costs it would recover from uwa on a party and party basis and the costs it had actually incurred in these proceedings.', \"it submitted that having regard to uwa's conduct in refusing its offer justice required that the difference in costs be borne by uwa.\", 'dr gray had no control over the conduct of uwa in responding to the sirtex offer.', '17 counsel for sirtex submitted that it was clear at the time that uwa refused the offer that it was seeking to maintain an untenable position under which it would have everything from everybody.', '18 in its written outline of submissions, sirtex acknowledged that the power to award indemnity costs is in the court\\'s discretion and would be exercised \"when the justice of the case so requires\": federal court of australia act 1976 (cth) s 43(2).', 'as sirtex put it the question for determination was whether it was unreasonable for uwa to reject its offer.', 'the reasonableness of the rejection was to be assessed:  (a) as at the date of the offer and on the basis of the evidence available at the time of the offer; but (b) with the benefit of hindsight as to the matters decided in the judgment.', 'a conditional offer to settle was properly the subject of consideration by the court.', \"19 sirtex set out a number of factors in favour of an award of indemnity costs:  (a) it would have been reasonable to expect uwa to accept sirtex's offer.\", '(b) uwa is in a significantly worse position as a result of running its trial against sirtex than it would have been had it accepted the offer.', '(c) assessed at the time of the offer, but with the benefit of hindsight (and even without the benefit of hindsight), uwa was highly unlikely to succeed in its claim.', '(d) it was entirely unnecessary for uwa to pursue a claim against sirtex when it had two other respondents with very substantial assets available to them which would have satisfied the claims of uwa realistically put at their highest.', '(e) uwa initiated the \"open offer\" regime as a means of seeking to gain an advantage in relation to any award of costs.', '20 sirtex, after referring to the absence of merit in the uwa case, submitted that the condition contained in its offer that uwa achieve \"substantial success\" against dr gray was, for two reasons, reasonable and prudent on the part of the board of a publicly listed company protecting innocent shareholders.', \"the case against sirtex was contingent upon uwa's succeeding against gray.\", 'that was self-evident on the pleadings.', 'secondly, uwa had maintained at all times that the conditions of substantial success would be satisfied.', '21 sirtex was a public company.', 'there was no question of its solvency at the time the open offer was made nor any need for security to be provided to support its offer.', 'sirtex submitted that in substance it was offering uwa a very substantial sum to resolve the matter as between them on a condition that uwa have substantial success against the alleged primary wrong doer.', 'this was in circumstances where uwa had secured the potential fruits of any judgment against gray and cri.', '22 sirtex referred to the dates at which affidavits of evidence were filed.', \"uwa's affidavits in chief were filed on 5 december 2006.\", \"dr gray's affidavit in chief was filed on 31 january 2007 and sirtex's affidavits on 20 and 21 december 2006.\", \"uwa, it said, had nearly three months to consider sirtex's evidence and six weeks to consider dr gray's evidence before the sirtex offer was made.\", 'the evidence referred to, it was said, should clearly have indicated to uwa that its case against sirtex was hopeless.', 'it was said to be clear on the evidence that:  1.', 'there was no implied contractual term conferring an interest on uwa in respect of intellectual property developed by dr gray.', '2.', 'although dr gray was conducting research for the benefit of some entity other than uwa there was no claim against him for breach of fiduciary duty on that account.', '3.', 'uwa had no capacity to alienate or interfere with substantive property rights by regulation.', '4.', 'the intellectual property regulations were not promulgated at the relevant time.', '5.', 'uwa had repeatedly failed to make a timely claim against sirtex.', '6.', \"professor barber's reply to the gorn letter was written in his capacity as acting vice chancellor.\", '7.', 'uwa adopted a deliberate strategy of withholding knowledge of a potential claim.', '8.', 'sirtex was not put on notice of the claim until october 2004.', '9.', 'the claim, when finally made, was misleading.', '10.', 'uwa advanced for the first time in its closing submissions the contention that sirtex was a volunteer but then decided not to press the submission.', '11.', \"uwa could not rely on dr gray's knowledge to claim against sirtex.\", 'this factor depends upon submissions on which no finding was made.', '12.', \"there was no answer to sirtex's defences based on estoppel, laches and delay.\", '13.', 'the relief sought by uwa was untenable.', '23 the preceding considerations were in part derived from findings made in the judgment.', 'some aspects involving uwa\\'s reliance upon dr gray\\'s knowledge to support its claim against sirtex and the absence of any \"answer\" to defences based on estoppel, laches and delay reflect an assumption that sirtex would have succeeded in relation to those matters.', 'that is not to say they would not have succeeded.', 'however there was no determination of those matters in the judgment.', \"24 sirtex submitted that to the extent that it had incurred costs on and after the closure of its open offer on 19 march 2007 commensurately dr gray's exposure under the cross-claim had increased.\", \"if the court were to accept its submissions that uwa's refusal to accept its offer was unreasonable, then it only seemed appropriate that the extra costs fall at the feet of uwa rather than dr gray.\", '25 in justification of its conduct in refusing to accept the sirtex offer, uwa made the following points:  1.', 'the sum offered was inclusive of costs and made shortly prior to the commencement of the trial at which time the parties had already incurred very substantial costs.', 'it was difficult for uwa to ascertain what, if any, amount was attributed in the offer to the value of its claims and what amount, if any, attributed to costs.', '2.', 'there was a real difficulty in ascertaining the value of the offer so as to compare it to the value of the relief claimed against sirtex.', 'a calculation of the value of the offer required uwa to assign values to the amount offered and the likelihood of various contingencies.', '3.', \"the sum offered did not vary according to the extent of uwa's success.\", '4.', 'the sum offered was contingent upon uwa succeeding in its claims against dr gray.', \"in the circumstances that have arisen where uwa failed against dr gray and sirtex failed in its cross-claim against uwa, uwa is only worse off than it would have been if it had accepted the offer in that it has now been ordered to pay sirtex's costs of the trial except insofar as they are referable to the costs of sirtex's cross-claim against dr gray.\", '5.', 'regardless of whether the offer was accepted by uwa, sirtex would still have been an active participant in the trial by reason of its cross-claim against dr gray.', '6.', 'the time for payment did not arise until after the conclusion of any appeal or time for appeal.', '7.', 'the court had not had occasion to consider the relief to which uwa would have been entitled if it had succeeded in establishing liability.', '8.', 'the offer was made on the eve of the trial and was expressed to be open for acceptance for a period of five days, representing in total three business days.', \"26 sirtex's submissions in reply, filed on 1 july 2008, referred to various cases for the proposition that in assessing the reasonableness of an offer the court should have regard to the ultimate analysis by the court of uncontroversial facts.\", \"the finding that there was an implication of law in dr gray's employment was based on essentially uncontroversial facts.\", \"27 in relation to the contingency attached to the offer, sirtex observed that uwa's case against it was necessarily a contingent one.\", 'the offer, if accepted, would have involved a real compromise on both sides:  (a) in a trial the size of the trial in these proceedings, the costs would be very substantial.', 'it would have been a major compromise for sirtex to forego its right to costs to that date from uwa.', \"(b) uwa was plainly materially worse off for having rejected sirtex's offer.\", \"it is liable for sirtex's costs.\", 'it has no chance of obtaining a payment of $1.5 million or an equivalent value of sirtex shares.', 'it has appealed against the dismissal of its application against dr gray and regards itself as entitled to succeed against him.', 'in those circumstances, it was submitted uwa could not say it was not worse off.', \"uwa had argued that it improved its position by running the trial because it succeeded against sirtex in respect of sirtex's cross-claims.\", 'but that cross-claim only arose if uwa succeeded in any of its claims.', '28 sirtex submitted there was no uncertainty as to the meaning of \"substantial success\" in the proposed deed.', 'the suggestion of uncertainty was only raised by uwa for the first time on 3 june 2008.', 'it did not suggest in march 2007 that it had any difficulty understanding the offer that had been put.', \"as to the date from which indemnity costs should be ordered, and in the light of mr price's correcting affidavit of 3 june 2008, that uwa rejected sirtex's offer on 15 march 2007, it was submitted that uwa should pay indemnity costs from that date.\", 'whether indemnity costs should be awarded  29 there have been a considerable number of decisions in the federal court and other courts about when indemnity costs will be awarded following the rejection of an open offer.', 'many of these cases turn on their own facts.', 'the starting point for consideration of the motion is the discretion in relation to costs conferred upon the court by s 43 of the federal court act.', '30 ordinarily that discretion will be exercised so that costs follow the event and are awarded on a party and party basis.', 'a departure from normal practice to award indemnity costs requires some special or unusual feature in the case: alpine hardwood (aust) pty ltd v hardys pty ltd (no 2) [2002] fca 224 ; (2002) 190 alr 121 at [11] (weinberg j) citing colgate palmolive co v cussons pty ltd (1993) 46 fcr 225 at 233 (sheppard j).', '31 order 23 provides for offers of compromise.', 'in this case it was not suggested that the sirtex offer complied with the requirements of o 23.', 'in any event that order is not a code.', '32 the general principles governing the exercise of the discretion to award indemnity costs after rejection by an unsuccessful party of a so called calderbank letter were set out in the judgment of the full court in black v lipovac [1998] fca 699 ; (1998) 217 alr 386.', 'in summary those principles are:  1.', 'mere refusal of a \"calderbank offer\" does not itself warrant an order for indemnity costs.', 'in this connection it may be noted that jessup j in dais studio pty ltd v bullet creative pty ltd [2008] fca 42 said that (at [6]):    if the rejection of such an offer is to ground a claim for indemnity costs, it must be by reason of some circumstance other than that the offer happened to comply with the calderbank principle.', ' 2.', 'to obtain an order for indemnity costs the offeror must show that the refusal to accept it was unreasonable.', '3.', 'the reasonableness of the conduct of the offeree is to be viewed in the light of the circumstances that existed when the offer was rejected.', '33 the preceding general principles inform the exercise of the discretion.', 'that discretion is not to be fettered by transformation of approaches and practices developed through the cases into quasi statutory rules.', 'in john s hayes amp; associates pty ltd v kimberly-clark australia pty ltd (1994) 52 fcr 201 , hill j said (at 203):  care must be taken not to circumscribe the discretion by reference to closed categories.', 'it is not a necessary condition of the power to award costs that a collateral purpose be shown.', 'the categories warranting the exercise of the discretion are not closed ... see also goldberg j in dr martens australia pty ltd v figgins holdings pty ltd (no 2) [2000] fca 602 at [15] .', '34 i accept that the making of a rolled up offer inclusive of costs and interest may detract from the weight to be given to its refusal in the exercise of the discretion.', 'finn j referred to authorities on the point in gec marconi systems pty ltd v bhp information technology pty ltd [2003] fca 688 ; (2003) 201 alr 55 at [34] .', 'his honour cited single judge decisions to the effect that such offers ought not to be a relevant consideration on the question of costs and would not be considered in the same way as a calderbank letter.', 'his honour was invited to depart from that line of first instance authority.', 'however he was not prepared to say it was clearly wrong.', 'notwithstanding that, in the circumstances of the case he had to decide, his honour found that:  the fact that the offer gave no indication at all of the breakdown ... between the claim, interest and costs blunts significantly the weight to be given the offer.', '35 while respecting the general approach to rolled up offers reflected in the cases to which finn j referred, such approaches cannot be calcified into rules of law which fetter a general discretion.', 'they simply reflect a common sense proposition that generally speaking such an offer is not unreasonably refused.', 'there may, however, be circumstances where a rolled up offer, refused by an applicant who is unsuccessful, may support a claim for indemnity costs.', '36 on the question of the level of unreasonableness necessary to attract the discretion, i respectfully agree with the comment of sackville j in seven network limited v news limited (2007) 244 alr 374 at [62] questioning the utility of substituting a requirement that rejection be \"plainly unreasonable\" for the requirement that it be \"unreasonable\".', 'given the evaluative character of the judgment involved the addition of the word \"plainly\" which is itself evaluative, has no useful function.', '37 at the time that sirtex made its offer to uwa the prospect of uwa succeeding against sirtex depended critically upon:  1.', 'uwa establishing its case against dr gray and, in particular, that he had breached his fiduciary duty.', '2.', 'uwa establishing that sirtex was accessorially liable in relation to that breach, a position that depended upon establishing that sirtex was aware of facts constituting (and which would have indicated to a reasonable person) the breach of fiduciary duties owed by dr gray to uwa.', '38 it cannot be said that uwa acted unreasonably in proceeding on the basis that it had a reasonable cause of action against dr gray.', \"true it is that the case as framed and presented depended upon an important proposition of law as to the existence of an implied term in the contract of dr gray's employment with uwa.\", 'but the correctness of that proposition had not previously been tested in australia in circumstances of the kind which arose in this case.', \"this is not a case, in my opinion, in which it is appropriate to take a hindsight test to the facts known to uwa at the time of sirtex's offer and conclude that it ought to have known that the law was against it.\", \"39 there were of course other hazards in the way of uwa's path to success against dr gray and therefore against sirtex.\", 'the question whether the relevant inventions were made while dr gray was an employee of uwa was one issue upon which findings adverse to uwa were made on all but the dox-spheres technology.', 'there was also a finding adverse to uwa that none of the sirtex directors, apart from dr gray, were on notice of a potential claim.', 'to establish any cause of action against sirtex based on knowing involvement in his alleged breaches of fiduciary duty would have depended entirely upon his role as a director of sirtex and whether his knowledge could be attributed to that company.', \"in addition, uwa faced substantial defences by sirtex based on uwa's delay in commencing proceedings after it first became aware of the facts relevant to its claimed causes of action.\", '40 the preceding factors may be seen as weighing to some degree in favour of the sirtex motion.', 'on the other hand the offer came as the trial commenced.', 'that is a factor, given the focus on the trial process which would then have existed, that militates against a finding of unreasonableness on the part of uwa in refusing the offer.', 'that conclusion is not affected by the fact that sirtex was making a counter-offer.', \"the counter-offer was not a variation on a theme opened by uwa's offers.\", 'it was quite different and could have been proposed earlier.', '41 it is also relevant that the offer made no break-up between recovery and costs and interest.', 'to that extent its refusal is less readily able to be characterised as unreasonable.', '42 uwa was entering into a complex piece of commercial litigation.', 'the initial letter of demand to sirtex indicated a level of confidence which was unrealistic given those complexities.', 'but that unrealistic level of confidence does not mean that it did not have an arguable case.', '43 there is a mix of factors in this case which are related to the exercise of the discretion which sirtex seeks to invoke.', 'some point one way, some another.', 'in the end i am not persuaded that the refusal of the sirtex offer by uwa was so unreasonable in the circumstances that i ought to award indemnity costs against it.', 'the motion for indemnity costs will be dismissed.', 'i certify that the preceding forty-three (43) numbered paragraphs are a true copy of the reasons for judgment herein of the honourable justice french.', \"associate:dated: 16 july 2008 counsel for the applicant: mr m zilko sc with mr d pratt   solicitor for the applicant: jackson mcdonald counsel for the first respondent: mr m bennett solicitor for the first respondent: lavan legal   counsel for the second respondent: mr jd elliott sc with mr ejc heerey and mr js emmett   solicitor for the second respondent: yeldham price o'brien lusk  date of hearing: 3 and 23 june 2008   date of judgment: 16 july 2008     austlii: copyright policy | disclaimers | privacy policy | feedback  url: http://www.austlii.edu.au/au/cases/cth/fca/2008/1056.html   \"]\n"
     ]
    }
   ],
   "source": [
    "dirpath = \"corpus/fulltext/\"\n",
    "files = [f for f in os.listdir(dirpath) if isfile(join(dirpath, f))]\n",
    "\n",
    "print(fp.get_sentences(files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9957069  -1.7302711  -1.2416555  -1.25041    -0.8760755   1.4730991\n",
      "  1.2059473   0.38232905 -1.6187527   1.305874    1.1770602   2.308416\n",
      "  0.02343252 -0.2502587   1.7815354  -1.332049    0.38943136 -2.052053\n",
      " -1.3515872  -1.5760187  -0.59295475 -0.66141963  1.3531227   0.47351202\n",
      "  0.80553395  2.9402657   2.2971811   0.9491949   4.030078    0.6117527\n",
      " -0.27292827 -1.1015353  -0.3637588  -1.0808604  -0.38145977 -2.5174286\n",
      "  1.1072197   2.530051    2.5857248  -1.1959172   1.7793411   0.09467691\n",
      " -1.4371932  -2.9791405   1.0630684   0.9067003   0.43923157  3.4134736\n",
      "  0.47711533 -1.3631905  -3.3734288  -0.2367886   0.3390342  -0.39412883\n",
      "  0.5333661   0.7227717   0.55354226  0.35878623  0.932402    2.4869206\n",
      " -0.55152404  2.4435148  -0.3364468  -1.9685099  -1.7815394  -0.6749915\n",
      "  2.4418046  -2.3903039   1.1918342   0.36871168 -1.7374214   0.7597355\n",
      "  1.6034806  -0.9551855   0.8539238  -1.5502286   0.8968359  -0.62780535\n",
      " -1.7566789   4.206336    0.92475533  0.4445385   1.4446664   0.18256582\n",
      "  0.33426532 -1.4212458   2.6209822   2.3302562   0.24014099  1.7833108\n",
      "  1.2331686   0.23349828 -3.6794689  -2.0452528  -0.9031459   0.8323558\n",
      " -0.8843479   0.30374396  0.87310374  3.1438227   1.6313096   1.6776122\n",
      "  0.48421437 -4.023881    3.1790373  -0.36640164 -1.5662786   2.1223414\n",
      "  2.1331837  -2.4567196   0.45546478  0.5395071  -1.0458131  -1.7282628\n",
      " -0.5866408  -0.7538245  -1.1013936   0.7281821  -0.9490656  -0.9584874\n",
      "  0.03865002  1.0363113   3.701328    1.6680748  -1.9616818   0.02108546\n",
      "  0.06672078  1.3992096  -1.1087863   0.8012173   1.5391992   0.5408178\n",
      "  0.942101   -0.39909512  0.17921649 -1.1100775   1.6705716   0.8876011\n",
      " -2.5764427   0.540361    0.12292239  1.3356769  -0.2826225  -0.77397394\n",
      " -1.3675452  -1.1290836  -2.5003982   2.3073096  -0.05056152 -1.0492153\n",
      " -0.10702924 -1.2159368   0.846608   -0.41358626 -0.83953726 -1.1248862\n",
      " -1.0842489  -0.39818436  1.2597241  -0.7062385  -3.208376   -1.7201724\n",
      " -0.8565359   0.6638217  -1.3636007  -3.1470718  -1.5880749   0.38425222\n",
      "  0.07932217  0.9742497   1.4434265   1.7713523  -1.6882014   1.6205076\n",
      " -4.433126   -1.5319406  -3.1952329  -1.1040304  -0.28445873  0.5716109\n",
      " -2.9582093   3.44765     2.682068   -1.5100415   0.10066229 -0.9557712\n",
      "  0.14830023  1.6512151  -0.39719307 -2.6286154  -1.2253991  -0.263822\n",
      " -2.4644768   0.3337611  -0.40415186  2.0325894  -1.2030413   0.39076445\n",
      " -0.7095663  -1.9799259 ]\n"
     ]
    }
   ],
   "source": [
    "stop_words_list=set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "##########loading dev2vec=============\n",
    "#doc2vec_impl.main();\n",
    "\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec.load('doc2vec_models/doc2vec.model')\n",
    "#start testing\n",
    "#printing the vector of document at index 1 in docLabels\n",
    "docvec = d2v_model.docvecs[files[0]]\n",
    "print(docvec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def read_data(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        word_vocab = set()  # not using list to avoid duplicate entry\n",
    "        word_count = {};\n",
    "        word_index={};\n",
    "\n",
    "        word2vector = {}\n",
    "        count=0;\n",
    "        for line in f:\n",
    "            line_ = line.strip()  # Remove white space\n",
    "            words_Vec = line_.split()\n",
    "            word_vocab.add(words_Vec[0])\n",
    "            word_index[words_Vec[0]]=count;\n",
    "            count=count+1;\n",
    "\n",
    "            word2vector[words_Vec[0]] = np.array(words_Vec[1:], dtype=float)\n",
    "    print(\"Total Words in DataSet:\", len(word_vocab))\n",
    "    return word_vocab, word2vector, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename):\n",
    "    dvocab, w2v,word_index  = read_data(filename);\n",
    "    return w2v,word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in DataSet: 400000\n",
      "Loaded embeddings\n",
      "reading data completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_array,word_index = load_embeddings(embedding_filename)\n",
    "print(\"Loaded embeddings\")\n",
    "\n",
    "# words_data=pd.read_csv(\"words_data.csv\");\n",
    "# catchphrases_data=pd.read_csv(\"catch_data.csv\")\n",
    "print(\"reading data completed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sen2vec embeddings\n",
    "def sen2vec(sentences):\n",
    "    embed = hub.Module(module_url)\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        sentenceEmbeddings = session.run(embed(sentences))    \n",
    "        return sentenceEmbeddings\n",
    "\n",
    "# sentence_embeddings = sen2Vec(['UWA was ordered to pay the costs of Dr Gra','Sirtex succeeded in its cross-claim against Dr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201534\n"
     ]
    }
   ],
   "source": [
    "print(word_index['unk'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statements(file):\n",
    "    with open(dirpath + file, 'r',encoding=\"utf-8\", errors='replace') as f:\n",
    "        data=str(f.read());\n",
    "        data=data.lower()\n",
    "        data = data.replace(\"\\\"id=\", \"id=\\\"\");\n",
    "        data=data.replace(\"\\n\",\"\")\n",
    "        data=data.replace('\".*?=.*?\"', \"\",)\n",
    "        data=data.replace(\"&\",\"\");\n",
    "        xml = ET.fromstring(str(data))\n",
    "        name=None;\n",
    "        rows_list=[];\n",
    "        catchphrases=[];\n",
    "        sentences=[];\n",
    "        for child in xml:\n",
    "            if child.tag==\"catchphrases\":\n",
    "                for catchphrase in child:\n",
    "                    id=catchphrase.attrib.get(\"id\")\n",
    "                    #print(catchphrase.text)\n",
    "                    catchphrases.append({\"file_id\":file,\"Name\":name,\"Id\":id,\"text\":catchphrase.text})\n",
    "                    #catchphrases+=tokenizer.tokenize(catchphrase.text)\n",
    "            if child.tag==\"sentences\":\n",
    "                for sentence in child:\n",
    "                    id = sentence.attrib.get(\"id\")\n",
    "                    sentences.append({\"file_id\":file,\"Name\":name,\"Id\":id,\"text\":sentence.text})\n",
    "                    #sentences+=tokenizer.tokenize(sentence.text)\n",
    "    \n",
    "    \n",
    "    #sentences = [w for w in sentences if not w in stop_words_list] \n",
    "    #catchphrases = [w for w in catchphrases if not w in stop_words_list]\n",
    "    \n",
    "    \n",
    "    #sentences=[word.lower() for word in sentences if word.isalphanum()]\n",
    "    #catchphrases=[word.lower() for word in catchphrases if word.isalphanum()]\n",
    "    \n",
    "    return sentences,catchphrases\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id      file_id  is_catchword                                words\n",
      "0       s0  08_1056.xml             0             [176, 13, 759, 396, 584]\n",
      "1       s0  08_1056.xml             0               [13, 759, 396, 584, 0]\n",
      "2       s0  08_1056.xml             0             [759, 396, 584, 0, 3250]\n",
      "3       s0  08_1056.xml             0             [396, 584, 0, 3250, 845]\n",
      "4       s0  08_1056.xml             0              [584, 0, 3250, 845, 21]\n",
      "5       s0  08_1056.xml             0                [0, 3250, 845, 21, 0]\n",
      "6       s0  08_1056.xml             0              [3250, 845, 21, 0, 221]\n",
      "7       s0  08_1056.xml             0                 [845, 21, 0, 221, 3]\n",
      "8       s0  08_1056.xml             0                 [21, 0, 221, 3, 556]\n",
      "9       s0  08_1056.xml             0                [0, 221, 3, 556, 603]\n",
      "10      s0  08_1056.xml             0           [221, 3, 556, 603, 201534]\n",
      "11      s0  08_1056.xml             0            [3, 556, 603, 201534, 98]\n",
      "12      s0  08_1056.xml             0         [556, 603, 201534, 98, 6456]\n",
      "13      s0  08_1056.xml             0        [603, 201534, 98, 6456, 3965]\n",
      "14      s0  08_1056.xml             0       [201534, 98, 6456, 3965, 3850]\n",
      "15      s0  08_1056.xml             0            [98, 6456, 3965, 3850, 5]\n",
      "16      s0  08_1056.xml             0        [6456, 3965, 3850, 5, 201534]\n",
      "17      s0  08_1056.xml             0         [3965, 3850, 5, 201534, 749]\n",
      "18      s0  08_1056.xml             0         [3850, 5, 201534, 749, 8196]\n",
      "19      s0  08_1056.xml             0       [5, 201534, 749, 8196, 201534]\n",
      "20      s0  08_1056.xml             0      [201534, 749, 8196, 201534, 15]\n",
      "21      s0  08_1056.xml             0      [749, 8196, 201534, 15, 201534]\n",
      "22      s1  08_1056.xml             0            [69579, 15, 1298, 4, 642]\n",
      "23      s1  08_1056.xml             0                [15, 1298, 4, 642, 0]\n",
      "24      s1  08_1056.xml             0              [1298, 4, 642, 0, 1138]\n",
      "25      s1  08_1056.xml             0                 [4, 642, 0, 1138, 3]\n",
      "26      s1  08_1056.xml             1              [642, 0, 1138, 3, 6456]\n",
      "27      s1  08_1056.xml             0             [0, 1138, 3, 6456, 3850]\n",
      "28      s1  08_1056.xml             0             [1138, 3, 6456, 3850, 5]\n",
      "29      s1  08_1056.xml             0           [3, 6456, 3850, 5, 201534]\n",
      "...    ...          ...           ...                                  ...\n",
      "4470  s246  08_1056.xml             0              [3498, 12, 41, 6915, 4]\n",
      "4471  s246  08_1056.xml             0              [12, 41, 6915, 4, 1060]\n",
      "4472  s246  08_1056.xml             0           [41, 6915, 4, 1060, 38412]\n",
      "4473  s246  08_1056.xml             0         [6915, 4, 1060, 38412, 1138]\n",
      "4474  s246  08_1056.xml             1           [4, 1060, 38412, 1138, 98]\n",
      "4475  s246  08_1056.xml             1      [1060, 38412, 1138, 98, 201534]\n",
      "4476  s247  08_1056.xml             0           [0, 3053, 10, 38412, 1138]\n",
      "4477  s247  08_1056.xml             1          [3053, 10, 38412, 1138, 43]\n",
      "4478  s247  08_1056.xml             1            [10, 38412, 1138, 43, 30]\n",
      "4479  s247  08_1056.xml             0        [38412, 1138, 43, 30, 201534]\n",
      "4480  s248  08_1056.xml             0            [41, 18428, 12, 0, 10998]\n",
      "4481  s248  08_1056.xml             0         [18428, 12, 0, 10998, 70836]\n",
      "4482  s248  08_1056.xml             0        [12, 0, 10998, 70836, 201534]\n",
      "4483  s248  08_1056.xml             0      [0, 10998, 70836, 201534, 9730]\n",
      "4484  s248  08_1056.xml             0  [10998, 70836, 201534, 9730, 30588]\n",
      "4485  s248  08_1056.xml             0     [70836, 201534, 9730, 30588, 32]\n",
      "4486  s248  08_1056.xml             0         [201534, 9730, 30588, 32, 7]\n",
      "4487  s248  08_1056.xml             0           [9730, 30588, 32, 7, 1446]\n",
      "4488  s248  08_1056.xml             0           [30588, 32, 7, 1446, 4522]\n",
      "4489  s248  08_1056.xml             0               [32, 7, 1446, 4522, 3]\n",
      "4490  s248  08_1056.xml             0                [7, 1446, 4522, 3, 0]\n",
      "4491  s248  08_1056.xml             0             [1446, 4522, 3, 0, 1997]\n",
      "4492  s248  08_1056.xml             0               [4522, 3, 0, 1997, 10]\n",
      "4493  s248  08_1056.xml             0               [3, 0, 1997, 10, 5064]\n",
      "4494  s248  08_1056.xml             0            [0, 1997, 10, 5064, 9431]\n",
      "4495  s248  08_1056.xml             0            [1997, 10, 5064, 9431, 3]\n",
      "4496  s248  08_1056.xml             0               [10, 5064, 9431, 3, 0]\n",
      "4497  s248  08_1056.xml             0            [5064, 9431, 3, 0, 26011]\n",
      "4498  s248  08_1056.xml             0             [9431, 3, 0, 26011, 868]\n",
      "4499  s248  08_1056.xml             0           [3, 0, 26011, 868, 201534]\n",
      "\n",
      "[4500 rows x 4 columns] ['indemnity costs', 'calderbank letter', 'refusal of offer', 'whether refusal unreasonable', 'variety of factors relevant to assessment of unreasonableness', 'indemnity costs refused', 'costs']\n",
      "time-taken: 4.90190577507019\n"
     ]
    }
   ],
   "source": [
    "sentences,catchphrases=get_statements(files[0])\n",
    "start=time.time()\n",
    "sentences, catch_words = fp.get_dataframe(pd.DataFrame(sentences),pd.DataFrame(catchphrases))\n",
    "print(sentences,catch_words)\n",
    "print(\"time-taken:\",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_index_matrices(sentence_indexes):\n",
    "    length=len(sentence_indexes);\n",
    "    \n",
    "    sentence_indexes=[word_index['unk'],word_index['unk']]+sentence_indexes+[word_index['unk'],word_index['unk']];    \n",
    "    out_indices=[]\n",
    "    for i in range(2,length):\n",
    "        out_indices.append(sentence_indexes[i-2:i+3]);\n",
    "        \n",
    "    return out_indices;\n",
    "\n",
    "def prepare_label_matrices(labels):\n",
    "    length=len(labels);\n",
    "    labels=[0,0]+labels+[0,0];\n",
    "    out_labels=[];\n",
    "    \n",
    "    for i in range(2,length):\n",
    "        out_labels.append(labels[i]);\n",
    "        \n",
    "    return out_labels;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_indexes_labels(sentences,catchphrases):\n",
    "    \n",
    "    sentence_indexes=[];\n",
    "    labels=[];\n",
    "    \n",
    "    for word in sentences:\n",
    "        if word in word_index:\n",
    "            sentence_indexes.append(word_index[word]);\n",
    "        else:\n",
    "            #print(\"unknown word\",word)\n",
    "            sentence_indexes.append(word_index['unk']);\n",
    "            \n",
    "    for word in sentences:\n",
    "        if word in catchphrases:\n",
    "            labels.append(1.0);\n",
    "        else:\n",
    "            #print(\"unknown word\",word)\n",
    "            labels.append(0.0);\n",
    "            \n",
    "    return sentence_indexes,labels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_sentences(file_name):\n",
    "    temp_data=full_data[(full_data.file_id==file_name) & full_data['Id'].str.startswith(('s'))]\n",
    "    return list(temp_data.text.values)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class CatchPhraseExtractor(object):\n",
    "\n",
    "    def __init__(self, graph):\n",
    "        self.total_loss=0.0\n",
    "        self.build_graph(graph)\n",
    "\n",
    "    def build_graph(self, graph):\n",
    "        print(\"generating graph\");\n",
    "\n",
    "        with graph.as_default():\n",
    "            \n",
    "            #feed_dict = {self.doc_embedding: doc_embedding, self.phrases_indices: phrases_indices, self.phrase_labels: phrases_label_matrix,\n",
    "            #self.sentence_indices:sentence_ids_to_indices, self.sentence_embeddings: sentence_embeddings}            \n",
    "            \n",
    "            \n",
    "            self.phrases_indices = tf.placeholder(tf.int32, shape=[None,5])\n",
    "            self.phrase_labels = tf.placeholder(tf.int32, shape=[None,1])\n",
    "            \n",
    "            W = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "            phrase_tensor = tf.nn.embedding_lookup(W, self.phrases_indices)\n",
    "            \n",
    "            self.sentence_ids_to_indices = tf.placeholder(tf.int32, shape=[None,1])\n",
    "            self.sentence_embeddings = tf.placeholder(tf.float32, shape=[None,200])\n",
    "            sentence_tensor = tf.nn.embedding_lookup(self.sentence_embeddings, self.sentence_ids_to_indices)\n",
    "            sentence_tensor=tf.reshape(sentence_tensor, [tf.shape(sentence_tensor)[0], 200])\n",
    "            \n",
    "                                                   \n",
    "            self.doc_embedding = tf.placeholder(tf.float32, shape=[1,200])\n",
    "            #document_tensor = tf.convert_to_tensor(np.array([self.doc_embedding for i in range(tf.shape(self.phrases_indices)[0])]))\n",
    "                     \n",
    "            phrase_tensor = tf.reshape(phrase_tensor, [tf.shape(phrase_tensor)[0], 1000])\n",
    "            conv_filter = tf.Variable(tf.truncated_normal((1000, 200), stddev=0.1));\n",
    "            word_tensor = tf.nn.relu(tf.matmul(phrase_tensor, conv_filter));\n",
    "            \n",
    "            #stacked_tensor = tf.concat(values=[word_tensor, sentence_tensor, document_tensor], axis=1)\n",
    "            stacked_tensor = tf.concat(values=[word_tensor, sentence_tensor], axis=1)\n",
    "                                                   \n",
    "            weights_input = tf.Variable(tf.random_normal((400, 100), stddev=0.2));\n",
    "            weights_input_2 = tf.Variable(tf.random_normal((100, 1), stddev=0.2));\n",
    "            \n",
    "            bias1 = tf.Variable(tf.random_normal((1, 100), stddev=0.2));\n",
    "            bias2 = tf.Variable(tf.random_normal((1, 1), stddev=0.2));\n",
    "            \n",
    "            self.sentence_values=self.MLP(stacked_tensor, weights_input, weights_input_2, bias1, bias2);\n",
    "            \n",
    "            prediction_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.phrase_labels,logits=self.sentence_values)\n",
    "            self.loss=tf.reduce_mean(prediction_loss)\n",
    "                               \n",
    "            #using the gradient descent optimizer\n",
    "            optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "            grads = optimizer.compute_gradients(self.loss)\n",
    "            #clipped_grads = [(tf.clip_by_norm(grad, 5), var) for grad, var in grads]\n",
    "            self.app = optimizer.apply_gradients(grads)\n",
    "\n",
    "            self.init = tf.global_variables_initializer()\n",
    "            \n",
    "    def MLP(self, stacked_tensor, weights_input, weights_input_2, bias1, bias2):\n",
    "        h1 = (tf.matmul(weights_input,stacked_tensor,transpose_a=True,transpose_b=True))\n",
    "        h1 = tf.add(h1, bias1)\n",
    "        h1 = tf.nn.tanh(h1)\n",
    "        h2 = tf.matmul(weights_input_2,h1,transpose_a=True,transpose_b=False)\n",
    "        h2 = tf.add(h2, bias2)\n",
    "        h2 = tf.nn.sigmoid(h2)\n",
    "        return tf.transpose(h2)\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self,total_loss):\n",
    "        total_loss=tf.convert_to_tensor(total_loss)\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            variables=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "            print(variables)\n",
    "        return total_loss, tape.gradient(tf.convert_to_tensor(total_loss), variables)\n",
    "        \n",
    "                                                   \n",
    "    def train(self, sess, num_steps):\n",
    "        self.init.run()\n",
    "        print(\"Initailized\")\n",
    "        start=time.time()\n",
    "        total_loss=0.0;\n",
    "        for file in files[:1]:\n",
    "            sentences,catchphrases=get_statements(file);\n",
    "            file_data_frame, catch_words = fp.get_dataframe(pd.DataFrame(sentences),pd.DataFrame(catchphrases))\n",
    "            print(\"Time taken:\",time.time()-start)\n",
    "            \n",
    "            #needs sentences list\n",
    "            sentences_list = fp.get_sentences(file) #indexes/order preserved\n",
    "            sentence_embeddings = sen2vec(sentences_list)\n",
    "            \n",
    "            print(\"Time taken:\",time.time()-start)\n",
    "            sentence_ids_to_indices = np.array([int(x[1:]) for x in list(file_data_frame['Id'].values)])\n",
    "            \n",
    "            \n",
    "            #phrase inputs and labels\n",
    "            phrases_indices = np.array(list(file_dataframe['words'].values))\n",
    "            phrases_label_matrix = np.array(list(file_dataframe['is_catchword'].values))\n",
    "            \n",
    "            \n",
    "            #doc embedding\n",
    "            doc_embedding = d2v_model.docvecs[file]\n",
    "            \n",
    "            \n",
    "            feed_dict = {self.doc_embedding: doc_embedding, self.phrases_indices: phrases_indices, self.phrase_labels: phrases_label_matrix, self.sentence_indices:sentence_ids_to_indices, self.sentence_embeddings: sentence_embeddings}            \n",
    "            print(\"sending inputs\");\n",
    "            #loss_val = sess.run([self.loss], feed_dict=feed_dict)  \n",
    "            _,loss_val,outputs = sess.run([self.app,self.loss,self.sentence_values], feed_dict=feed_dict)\n",
    "\n",
    "            print(\"Train Finished: loss_val=\", loss_val)\n",
    "            for i in range(len(outputs)):\n",
    "                print(outputs[i])\n",
    "            \n",
    "        \n",
    "    def load_embeddings(self,embedding_array):\n",
    "        sess.run(self.embedding_init, feed_dict={self.embedding_placeholder: np.asarray(list(embedding_array.values()))})\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(inputs):\n",
    "    out=np.zeros((len(inputs),200));\n",
    "    for i in range(len(inputs)):\n",
    "        try:\n",
    "            c = w2v[inputs[i]]\n",
    "        except KeyError:\n",
    "            c = np.zeros((1,200));\n",
    "        out[i]=c;\n",
    "    \n",
    "    return np.transpose(out);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating graph\n",
      "time taken: 2.4080276489257812e-05\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "model = CatchPhraseExtractor(graph)\n",
    "start=time.time()\n",
    "\n",
    "#print(fp.get_dataframe(files[0]))\n",
    "#sentences_list = fp.get_file_sentences(files[0]) #indexes/order preserved\n",
    "#sentence_embeddings = sen2vec(sentences_list)\n",
    "end=time.time()\n",
    "print(\"time taken:\",end-start);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initailized\n",
      "Time taken: 4.4289469718933105\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/var/folders/38/3kwpqlj11153rrh6wl934p5r0000gn/T/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/tfhub_module.pb; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7578aca07192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#global_step = tf.train.get_or_create_global_step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#optimizer.apply_gradients(zip(grads, model.variables), global_step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-35b52eddf114>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, num_steps)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m#needs sentences list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0msentences_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#indexes/order preserved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0msentence_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msen2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3d0567887611>\u001b[0m in \u001b[0;36msen2vec\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#sen2vec embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msen2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m    104\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_module_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36mas_module_spec\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnative_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown module spec type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_hub/native_module.py\u001b[0m in \u001b[0;36mload_module_spec\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mmodule_def_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_def_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_def_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mmodule_def_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_def_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmodule_def_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleDef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFORMAT_V3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 85\u001b[0;31m             compat.as_bytes(self.__name), 1024 * 512, status)\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /var/folders/38/3kwpqlj11153rrh6wl934p5r0000gn/T/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/tfhub_module.pb; No such file or directory"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "  \n",
    "    #model.load_embeddings(embedding_array)    \n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    #global_step = tf.train.get_or_create_global_step()\n",
    "    for i in range(1):\n",
    "        model.train(sess, 10)\n",
    "    #optimizer.apply_gradients(zip(grads, model.variables), global_step)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
